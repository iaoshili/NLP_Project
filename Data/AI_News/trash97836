Aim higher, reach further.
Get the Wall Street Journal $12 for 12 weeks. Subscribe Now
http://www.wsj.com/articles/artificial-intelligence-isnt-a-threatyet-1418328453
1437
555
Artificial Intelligence Isn’t a Threat—Yet
Superintelligent machines are still a long way off, but we need to prepare for their future rise
ENLARGE
A machine doesn’t have to be superintelligent to do a lot of damage, if it is sufficiently empowered. Pictured, Joaquin Phoenix in the film ‘Her.’ Warner Bros. Pictures/Everett Collection
By
Does artificial intelligence threaten our species, as the cosmologist Stephen Hawking recently suggested? Is the development of AI like “summoning the demon,” as tech pioneer Elon Musk told an audience at MIT in October? Will smart machines supersede or even annihilate humankind?
As a cognitive scientist and founder of a new startup that focuses on “machine learning,” I think about these questions nearly every day.
But let’s not panic. “Superintelligent” machines won’t be arriving soon. Computers today are good at narrow tasks carefully engineered by programmers, like balancing checkbooks and landing airplanes, but after five decades of research, they are still weak at anything that looks remotely like genuine human intelligence.
Related Reading
Even the best computer programs out there lack the flexibility of human thinking. A teenager can pick up a new videogame in an hour; your average computer program still can only do just the single task for which it was designed. (Some new technologies do slightly better, but they still struggle with any task that requires long-term planning.)
A more immediate concern is that a machine doesn’t have to be superintelligent to do a lot of damage, if it is sufficiently empowered. Stock market flash crashes are one example: Hundreds of millions of dollars have been lost in minutes as a result of minor, difficult-to-completely-eliminate bugs.
The clear and present danger, if not the greatest long-term danger, is that mediocre computer programs can cause significant damage if left unchecked. What will happen, for example, when nearly perfect—but still imperfect—software controls not just stock trades but driverless cars? It’s one thing for a software bug to trash your grocery list; it’s another for it to crash your car.
None of this means that we should abandon research in artificial intelligence. Driverless cars probably will cause some fatalities, but they also will avert tens of thousands of deaths. Robotic doctors (perhaps a couple of decades away) may occasionally make bad calls, but they will also bring high-quality medicine to places that would otherwise lack trained doctors. Banning AI could squander a chance to save or radically enhance millions of lives.
Still, the scalability of AI—a single program can be replicated millions of times—means that each new program carries risks if it has access to the outside world. The more autonomy that we give to machines, the more we need to have safeguards in place. A program “sandboxed” on your iPhone, with no real access to the outside world, isn’t of much concern. A program that places stock trades needs more safeguards. A general-purpose robot that lives in your home, with full access to the Internet, would need vastly more.
The trouble is, nobody yet knows what that oversight should consist of. Though AI poses no immediate existential threat, nobody in the private sector or government has a long-term solution to its potential dangers. Until we have some mechanism for guaranteeing that machines never try to replace us, or relegate us to zoos, we should take the problem of AI risk seriously.
Computers have become much better at many things over the last decades, from chess to arithmetic to network trafficking, but so far they have not shown the slightest interest in us or our possessions. If this remains the case, there is every reason to think that they will continue to be our partners rather than our conquerors. We could be worried about nothing.
But the alarmists have a point, too. The real problem isn’t that world domination automatically follows from sufficiently increased machine intelligence; it is that we have absolutely no way, so far, of predicting or regulating what comes next. Should we demand transparency in programs that control important resources? Fund advances in techniques for “program verification,” which tries to make sure that programs do what they are designed to do? Outlaw certain specific, risky applications?
For now, anyone can write virtually any program at any time, and we have scarcely any infrastructure in place to predict or control the results. And that is a real reason for worry.
—Dr. Marcus is a professor of psychology and neuroscience at New York University and CEO of Geometric Intelligence. His latest book is “The Future of the Brain.”
1437
555
Artificial intelligence is man made ,... and is subhuman ... a human is always in control and its expertize depends on how intelligent and experience the user is.
Gods are used for the unknown ... prayer is a goodie program ... makes one feel good to pray ... and does nothing for those or that which is supposed to receive the prayer.  Of course if something does happened we call it a miracle ... such as you pray you find your lost keys:  Miracle.
Mars doesn't want our women. AI wants our dollars.
In many ways software technology has not advanced much since the 1960s when we started using third generation programming languages to program computers. We first need both the raw computing power in terms of memory and processing speed and we need software that can understand the environment and learn new and improve itself over the programming it started with. I think when this happens, society will need to mandate some kind of an Off switch in both the hardware and software beyond the program verification for whatever tasks it was built to perform.
@Terry P. Carriker You may be in for a very rude surprise when your AI begins to communicate with God and realizes how uninteresting you are in comparison.
If computers did become self-aware, would they revere their makers as a gods?  Would they be thankful and revere us?  Or would they see us as some sort of pestilence to be exterminated, or at best a nuisance to be humored.  Perhaps a ward, or pet.  What would their reason for living be? What kind of moral system would they create?
Apply Asimov's Three Laws of robotics to AI:
1 A robot may not injure a human being or, through inaction, allow a human being to come to harm.
2 A robot must obey the orders given to it by human beings, except where such orders would conflict with the First Law.
3 A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.[1]
It is a self programming recursive algorithm.
The real threat is a massive government program
that would spend billions to replicate the brain of a cow.
Humans are cheap to produce and can also sing and dance.
The article is really about "hard" AI, but he uses "soft" AI examples because that's what we have now.  The central question there is whether the human brain/mind is a Turing machine.  If it is, then its processes will eventually be simulated on other Turing machines, similar to the ones we program today.  If it isn't, the human brain/mind are a different order of thing, then the equivalent is impossible.  I tend toward the latter on the basis that human intelligence can determine that a problem is undecidable, while a computer cannot. This is a far longer discourse than I can write here, but you get the idea, if you're in the field.
 For one of the most interesting books on the subject of consciousness, have a look at The Physics of Consciousness, by Evan Harris Walker.  He discusses quantum processes at the synapse level, where there really are undecidable events.
@John Cole  It is interesting how the educated mind avoids undecidability. We are not just Turing contraptions.  The egg of a fruit fly has more processing power than all the computers on the planet.
@John Cole John, I don't quite buy your argument with respect to the meta-problem of determining that a another problem is undecidable.  It seems to me that for humans to make this determination, the meta-problem
would have to be decidable and therefore machine computable.   Just because a process is undecidable does not mean it can decide the undecidable.
The book you refer to looks interesting.  I'll check it out.
In 1965 my devoute Catholic Church going Fourth Degree Knights of Columbus grandfather fold us kids that the Beattles will be the downfall and the mankind.
He hasn't been wrong yet.
Nothing can compare to the human brain ... or brains ... Einstein, Guttenberg, the computer, the Holocaust, artificial limbs, the Wright brothers, Henry VIII, the First Emperor of China, the Aztecs and so many others ... we need to relook our past for discoveries we haven't had the experience and intelligence as of yet to uncover ... artificial intelligence ... artificial and helpful: But not equivalent to the Brain. 
@Bob Washick You didn't mention the Beatles, or lingerie football.
Dear Dr. Marcus:
The most immediate danger from AI is not even mentioned in your article.
The most immediate danger from AI is MASS UNEMPLOYMENT. 
AI will take over a large percentage of the JOBS that humans do and by which they earn a living.
AI is not only doing the work of production people in the factories "BUT ALSO" the work of Doctors, Lawyers, Engineers, Accountants, Software Programmers, Radiologists, Architects and other highly-educated and highly-paid people. And this will get worse.
Long before AI makes Humans EXTINCT, 
AI will make them JOBLESS.
Without jobs, they will be without money, without food, without shelter, without medical care, without hope.
There will be warfare between the few employed and the many unemployed.
It will be dangerous to have a job.
This will be a HUGE SOCIAL PROBLEM.
And it needs to be addressed NOW.
Please tell us what is being done about this social problem.
Tom, I generally agree with you except for the automatic  characterization of it as a danger. It can be, yes. But it can also be a  fantastic opportunity. Ray Kurzweil wrote of this (too optimistically  imo) in his book The Singularity Is Near.
Also  parts of your predictions seem to be impossible. If wealth disparity  (or jobs) became as dramatic as you suggest, demand for production would  collapse as well in which case investment in automation would stop.  There is an inherent negative feedback loop (that's a good thing) in the  system.
@Tom Mactague A very similar argument was made when telephone exchanges were automated.  That advancement threw hundreds of thousands of young women, who were the ones connecting the calls manually, out of work.  A similar argument has been made for every advance in technology.  Yet the net effect is to improve everyone's quality of life.  Humans are nothing if not adaptable, especially when they're young. 
This said,  I still hope you are right.
@Tom Mactague   One thing I can predict about the future is that whatever happens will not be a linear progression from where we are now.  Any idiot can do linear extrapolation, which is how we get so much junk science and government programs.
The real economic question is not whether people are employed at the level and in the sense that they are today, but rather how many hours of work it takes to produce the goods and services to support our current societal lifestyle.  If that can be done with 10 hours per week for the workforce, great.  Remember that the 40-hour workweek was an invention of the last century, and that farming is seasonal, with lots of work in spring and fall, and less (but not none) during the rest of the year.  Again, humans are nothing if not adaptable. 
"Exciting times, they are a-coming"
and it's not a linear extrapolation from where we are today. Any idiot can do that.
Compare the best we humans can do with computers to the programming and intelligence of animals. We're not coming close to what God has created and programmed in the animal kingdom. And there are so many other things to worry about than artificial intelligence in this fallen world which has an expiration date. 
"- - -  Fund advances in techniques for “program verification,” which tries to make sure that programs do what they are designed to do? - - - "
Like ALL software testing, testing should make sure that programs do what they are supposed and NOT DO WHAT THEY ARE NOT SUPPOSED TO DO !!!
The part in Caps is often forgotten during testing.
This is especially true for AI software.
Bob Tom user 5pts
How do you reply?
I speculate that silicon based electronics will eventually reach a capability plateau, which may be years away from now. The real advance in AI will probably come with a joining of organic neuronal networks and silicon in some way. Today that is considered science fiction, like cyborgs. But in the 1930's & 40's Dick Tracy's 2-way wrist radio was considered science fiction too and look at smartphones today.
Whenever the technology evolves to that point there will be a fortune to be made in software by having a machine capable of writing program code simply by telling it what you want your program to do. Imbuing a machine to create and modify that which it creates is what "thinking" is all about. The danger is that at some point machines reach a sensory threshold of human-like self-awareness. Coupled with the ability to create systems capable of exercising control over  behavior could be problematic without an ability to "pull the plug" at any time. 
Hawking may be a genius, but he did not say anything in the quoted statement. AI, like the quest for a unified theory, is a scientific pipe dream. 
A better statement may have been, "humans are in no danger in being taken over by replicants"
Artificial intelligence is already a menace.  It resides in the White House.
Here is an example of how sophisticated a human brain is. I have a six foot high fence in the backyard, made of 4" planks, a half inch apart.
As I sit on my deck about 80 ft. from the back fence, I can see the neighbors dog as he runs along side and behind my fence.  It is almost as if the fence become opaque, but only when the dog is running. 
My brain is seeing the changing outline of the dog in the spaces between the boards and interpolating the image as the dog passes by each space. I did not teach myself how to do that, that ability just came with the brain and the eyes. Amazing and fantastic real-time computing done without effort.
Great article.
When it comes to knowing what to believe in this area, I rather listen to geniuses like Stephen Hawking and Elon Musk than to the right-wing idiots who spend their entire days posting nonsense on the WSJ comment board...
@Ted Martin Is this coming from a left-wing idiot who spends his entire day reading comments from right-wing idiots?
Jack Armstrong user 5pts
This article is silly.
1.  There is no true AI in our immediate future. An expert system is no where close to being a self aware AI capable of expanding its own knowledge.
2.  The first AI will probably be like an idiot savant.  Able to do things like math really quick, but very slow to understand and solve more sophisticated, abstract problems because of the enormous amount of computing required.
1. That's what the author said.
2. A computer is the Jeopardy champion. Your "first" hurdle has been surmounted (actually many times) and was, as you point out, a savant. But, what's your point?
With regard to your later comment about what you can perceive through gaps in a fence, evolution had several billion years to build our brains. Are you really going to come to a conclusion of "silly" based on no more than about 200 years of efforts at computer intelligence?
Machines will spell the end of the human race the day they can hold 4 minutes-of-angle or better with a service rifle from prone.  Like even frail, fat geezers like I can.  Until then, even my old dog yawns.
@Robert Eisenhauer   Machines will not end the human race.  But they may be its future.  As they are our children, how is this not 'human' evolution?
Mankind needs Morpheus and Neo to stop this before it begins
Will not AI necessarily have similar decision making characteristics to those that write its code?  The programmers will be similar to its parents.  Who will decide who creates AI, those that believe they know what is best for us?  Like those in Washington?
There are human beings alive today capable of doing what the Bible claims Jesus did -- and more. "The human nervous system is the most marvelous thing in the universe", to paraphrase a late great Vedic Teacher. 
Jesus was a human being like the rest of us but with a purer, more cultivated nervous system. He was not, however, the most highly evolved human ever. Others have evolved far higher and they also gained a deeper understanding of the mechanics of consciousness. But only a very few of them saw any point in teaching the likes of you and me. Obviously, they had a point.
Patanjali's Yoga sutras, desires introduced at the very point where the unmanifest becomes manifest, are fulfilled immediately, like water into wine, levitation, travel to anywhere. Predicting the future is the exception. "The path of action is unfathomable". 
With fully functioning humans like them around, machines haven't a chance.
And the "aliens" most likely to be encountered "out there" will be us.
@lucas watson /  The Christian world is also one that was created in 6 days with Earth at its center, a world where Neanderthals, Homo erectus, and Homo habilis have no place in history, where dead people rose out of their graves, walked about the city and conversed with the living, a place where demons could enter pigs and cause them to run off a cliff and drown themselves, where two bears can maul and kill 42 children, a place where a woman can conceive and deliver while remaining a virgin, where the act of sending dead people to a place of eternal torture can be seen as a just punishment for living an ordinary human life, a place where angels interact with the local citizenry and make important proclamations, where slavery is held up as an honorable ‘enterprise,’ where women are a form of property, and where rebellious children, adulterers, and homosexuals are considered so evil that they deserve to be stoned to death.
And finally it is a world where God feels that he must kill his own son because he can find no other way to forgive people of their sins.
Yes, this seems like a very strange world to anyone alive today. It should take only a few moments of reflection to understand, to grasp, to figure this whole thing out, that the god of Christianity is to adults as Santa Claus is to children- an imaginary friend.
@lucas watson   @Terry P. Carriker  /   The surest sign of a man-made enterprise is that it splits quickly into many different factions.  On the other hand, one initiated by a god would be expected to converge into a tight unity. This is because only those groups that aligned correctly with the divine theological blueprint would receive supernatural support and thereby flourish, attract members, and survive the long term.  Any wayward factions would lose favor and couldn’t compete for new members.
There are now approximately 38,000 Christian denominations, many of which have very disparate beliefs and practices.  This is a valid clue that Christianity is a man-made concept.
"It should take only a few moments of reflection to understand, to grasp, to figure this whole thing out,"
Well, you need to go back to the proverbial drawing board because based upon your screed you haven't figured anything out. Someday you may be in for a very rude awakening! 
I have never read where Jesus spoke of the Bible -- predicting it. I'm pretty sure he anticipated it but didn't mention it because he knew it would hurt as much as help. Post Jesus, his words helped very few.
But even more corrupted than Christianity is the Veda. The greater the enlightenment, the more it attracts charlatans and pretenders.
Speaking to people in order to lift them up has been extraordinarily unsuccessful. But Hollywood, Leftist preaching, etc, reaching people through their feelings, has been very effective but terrifying since it's been used almost entirely for destructive purposes. And
yet humans find their way forward because we all have the resources the enlightened have, just to a lesser degree.
Show More Archives
Copyright ©2015 Dow Jones & Company , Inc. All Rights Reserved.
Copyright 2014 Dow Jones & Company, Inc. All Rights Reserved
