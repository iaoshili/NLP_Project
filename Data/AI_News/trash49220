Subscribe
Get 10 issues a year and save 65% off the cover price.
New research highlights the distinction between how artificial intelligence sees and how it knows what it's looking at.
Dec 15, 2014
Computers, like people, understand what they see in the world based on what they've seen before.
And computer brains have become really, really good at being able to identify all kinds of things. Machines can recognize faces, read handwriting, interpret EKGs , even describe what's happening in a photograph. But that doesn't mean that computers see all those things the same way that people do.
This might sound like a throwaway distinction. If everybody—computers and humans alike—can see an image of a lion and call it a lion, what does it matter how that lion looks to the person or computer processing it? And it's true that ending up at the same place can be more useful than tracing how you got there. But to a hacker hoping to exploit an automated system, understanding an artificial brain's way of seeing could be a way in.
A team of computer scientists from the University of Wyoming and Cornell University recently figured out how to create a whole class of images that appear meaningful to computers but look like TV static or glitch art to the human eye. "It is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art [deep neural networks] believe to be recognizable objects," they wrote in a paper that's currently under peer review and has been posted to ArXiv , where scientists post preprints of papers while they are being reviewed.
And not only do computers recognize signals in the noise, they do so with a huge amount of confidence. So that while you see images that look like this...
Image derived from Nguyen, Yosinski, Clune paper  
...a computer's brain, or deep neural network (DNN), says it is 99 percent sure that it sees in those same images a gorilla, and an arctic fox, and a bikini, and an eel, and a backpack, and so on.
Screenshot from Nguyen, Yosinski, Clune paper  
"To some extent these are optical illusions for artificial intelligence," co-author Jeff Clune told me via gchat. "Just as optical illusions exploit the particular way humans see... these images reveal aspects of how the DNNs see that [make] them vulnerable to being fooled, too. But DNN optical illusions don't fool us because our vision system is different."
Clune and his team used an algorithm to generate random images that appeared unrecognizable to humans. At first, Clune explains, the computer might be unsure about what it was seeing: "It then says, 'That doesn't look like much of anything, but if you forced me to guess, the best I see there is a lion. But it only 1 percent looks like a lion.'"
"People could embed messages discussing freedom of the press and get them past communist AI-censoring filters by making the image look like the communist party flag!"
From there, the researchers would continue to randomly tweak the image's pixels—which remained unidentifiable to humans—until the computer said it could identify, with almost complete certainty, the image as a familiar object. And though the image would still appear nonsensical to the human eye, it would represent, Clune says, the Platonic form of whatever the computer sees. And this is a key point: Because it's not that the computer is identifying the image incorrectly per se, it's that a computer sees and thinks about the identifying components of any given thing differently—and more granularly—than a human does. "One way to think about it is this," Clune told me. "These DNNs are fans of cubist art. They want to see an eye, a nose, and a mouth in the image to call it a face, but they don't particularly care where those things are. The mouth can be above the eyes and to the left of the nose."
But while humans squinting at the same blocks of color in a Paul Klee painting might identify different familiar objects— what looks like a duck to me might look like a rabbit to you—DNNs will look at the same seemingly abstract image and derive the same meaning. "We tried exactly that and it works," Clune said of testing the same illusion against multiple neural networks. "Two different DNNs will both look at the same TV-static and say, 'Yep. Definitely a lion.'"
A human looking at a lion is making split-second categorizations as electrical signals travel along the optic nerve to the brain: Okay, it's an animal. It's big. It walks on four legs. It has a tail. It has a sandy mane—oh, that's a lion. A computer brain's checklist is more refined. Instead of looking for retractable claws and sharp teeth, artificial intelligence assesses lionishness at the pixel level. Which means an image that looks like a snowy monitor to a human brain may look quite clearly like a big cat to a computer brain, sort of like how you might see (or not) a hidden sailboat in a Magic Eye poster.
Instead of looking for retractable claws and sharp teeth, artificial intelligence assesses lionishness at the pixel level.
And because these computers see illusions the same way, there are significant implications for digital security, surveillance, even human communications. "For example, Google image search filters out X-rated images automatically," Clune said. "Using the technique we describe, a shady company could make images that look to Google's artificial intelligence filters like rabbits, but that actually contain nudity or other illicit imagery."
To people in countries where governments restrict speech and publishing, citizens could theoretically communicate secretly by leveraging the opacity within deep neural networks. Clune: "People could embed messages discussing freedom of the press and get them past communist AI-censoring filters by making the image look like the communist party flag!"
Even when computers can be trained that what they're seeing isn't, as far as a human is concerned, the thing the computer thinks it sees—it's easy to retrain the computer to be fooled all over again, which, for now, leaves such networks vulnerable to hackers. Understanding such opportunities for exploitation will be critical as artificial intelligence becomes increasingly pervasive.
In the meantime, Clune says his team's findings have underscored limitations in the human way of seeing. "This work has caused me to reflect on how we see even more deeply," he said. "Do I focus on the low-level details only sometimes? Only on the high-level structure and ignore the details?"
Exercises in perspective aside, the larger promise of deep neural networks, Clune says, is astonishing. "They have already, and will—more than you can imagine—change the course of human history."
May 6, 2015
About the Author
Adrienne LaFrance is a senior editor at The Atlantic, where she oversees the Technology section. Previously she worked as an investigative reporter for Honolulu Civil Beat , Nieman Journalism Lab , and WBUR .
George Lucas is not involved with the creation of Star Wars: The Force Awakens. When interviewed by Stephen Colbert about the forthcoming sequel, the now-retired filmmaker said "I'm excited, I have no idea what they're doing"—they being director J.J. Abrams and his team.
But according to Bruce Handy's new Vanity Fair cover story on the creation of Episode VII, Lucas at one point did have a vision for the story that the new Star Wars film would tell. By the time he sold Lucasfilm and related properties to Disney for more than $4 billion, he’d “sketched out ideas for episodes VII, VIII, and IX,” writes Handy, and had already approached Harrison Ford, Carrie Fischer, and Mark Hamill about being involved. Once the property was in Disney’s hands, though, the company and executive producer Kathleen Kennedy mostly scrapped Lucas's ideas. Why? Apparently, people involved may have been getting flashbacks to child actor Jake Matthew Lloyd’s performance in the first prequel:
Since Citizens United, members of Congress have been increasingly engaged in a never-ending campaign to snare their share of cash flooding the political marketplace. But last week Chief Justice John Roberts deserted his conservative brethren, writing an opinion that offers Congress a roadmap for cleaning up campaign finance. If Congress embraces Roberts’s support for a ban on judges personally soliciting campaign contributions, and applies it to its own members, it can bring “dialing for dollars” to a decisive end.
On the surface, the case of Williams-Yulee v. Florida Bar only involves judicial elections. To preserve the impartiality of its judges, Florida had barred candidates from personally soliciting funds—requiring them to delegate this task exclusively to their campaign committees. In upholding that ban, Roberts emphasized that judicial candidates had complete freedom to speak on any issue; they simply were barred from saying: “Please give me the money.”
Nobel laureate John Steinbeck (1902-1968) might be best-known as the author of East of Eden, The Grapes of Wrath, and Of Mice and Men, but he was also a prolific letter-writer. Steinbeck: A Life in Letters constructs an alternative biography of the iconic author through some 850 of his most thoughtful, witty, honest, opinionated, vulnerable, and revealing letters to family, friends, his editor, and a circle of equally well-known and influential public figures.
Among his correspondence is this beautiful response to his eldest son Thom's 1958 letter, in which the teenage boy confesses to have fallen desperately in love with a girl named Susan while at boarding school. Steinbeck's words of wisdom—tender, optimistic, timeless, infinitely sagacious—should be etched onto the heart and mind of every living, breathing human being.
“Don’t underestimate me,” declared newly announced presidential candidate Bernie Sanders to George Stephanopoulos on Sunday. That may be good advice.
By conventional standards, Sanders’s candidacy is absurd: He’s not well known, he doesn’t have big money donors, he’s not charismatic, and by Beltway standards, he’s ideologically extreme. But candidates with these liabilities have caught fire before. Think of Jerry Brown, who despite little funding and an oddball reputation outlasted a series of more conventional candidates to emerge as Bill Clinton’s most serious challenger in 1992. Or Pat Buchanan, who struck terror in the GOP establishment by winning the New Hampshire primary in 1996. Or Howard Dean, who began 2003 in obscurity and ended it as the Democratic frontrunner (before collapsing in the run-up to the Iowa Caucuses). Or Ron Paul, who in 2012 finished second in New Hampshire and came within three points of winning Iowa.
For fans of Joss Whedon, plenty of the writer-director’s signature flourishes were on display in his latest foray into superhero blockbusterdom , The Avengers: Age of Ultron—the humorous banter, the sudden reversals, the clever callbacks. (That scene with the Vision and Thor’s hammer offered perhaps the movie’s second-best moment, behind only … the initial scene with the hammer.)
But in the run-up to the film, the most nervously anticipated Whedon trope was the filmmaker’s longstanding penchant for killing off characters to whom viewers had grown attached.
This compulsion dates all the way back to the shocking death of Jenny Calendar in the second season of Buffy the Vampire Slayer in 1998. Over the years, a couple of particular sub-variations on the theme have become evident. First, Whedon enjoys killing off characters on the cusp of a long-awaited romantic fulfillment: Ms. Calendar and Tara on Buffy; Fred (who died in Wesley’s arms) and Wesley (who, perversely, died episodes later in Fred’s arms) on Angel; Penny in Dr. Horrible’s Sing-Along Blog, etc.
In 2011, Pennsylvania's then-Republican governor, Tom Corbett, proposed slashing the state's entire higher-education funding by hundreds of millions of dollars, including 50 percent of spending on institutions such as Penn State and Temple. At the time, the proposal was unprecedented in America, and Corbett quickly became one of the most notorious figures in public education. Students and faculty rallied. Advocacy groups and labor coalitions launched campaigns. Even President Obama eventually chimed in .
Ultimately, the Pennsylvania legislature struck a compromise with Corbett, agreeing to cuts of about 18 percent . But Corbett's would-be budget, along with his subsequent proposals to reduce public-education spending, may have doomed him from the get go: In a landslide vote last year, the one-term governor lost his bid for reelection. Political analysts largely attributed Corbett's downfall to his approach to education.
There are two concurrent debates about the National Security Agency's bulk collection of telephone metadata. One is whether the program violates the Fourth Amendment because it's a warrantless search or seizure. The second is a statutory question: Does the law Congress passed authorize it in the first place?
A panel of federal judges on the Second Circuit Court of Appeals ruled Thursday morning in ACLU v. Clapper that the collection program isn't authorized by Section 215 of the PATRIOT Act, which the government has cited to justify the program. In short, the judges ruled that the law doesn't allow the government to collect domestic phone records, because that's not what Congress authorized in the first place.
Subscribe
Get 10 issues a year and save 65% off the cover price.
I want to receive updates from partners and sponsors.
Insights powered by Parsely
